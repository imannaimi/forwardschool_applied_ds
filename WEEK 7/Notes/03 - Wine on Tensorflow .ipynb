{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('Data/Wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0    14.23        1.71  2.43          15.6        127           2.80   \n",
       "1    13.20        1.78  2.14          11.2        100           2.65   \n",
       "2    13.16        2.36  2.67          18.6        101           2.80   \n",
       "3    14.37        1.95  2.50          16.8        113           3.85   \n",
       "4    13.24        2.59  2.87          21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   OD280  Proline  Customer_Segment  \n",
       "0   3.92     1065                 1  \n",
       "1   3.40     1050                 1  \n",
       "2   3.17     1185                 1  \n",
       "3   3.45     1480                 1  \n",
       "4   2.93      735                 1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>178.0</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>11.03</td>\n",
       "      <td>12.3625</td>\n",
       "      <td>13.050</td>\n",
       "      <td>13.6775</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic_Acid</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.6025</td>\n",
       "      <td>1.865</td>\n",
       "      <td>3.0825</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.5575</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>10.60</td>\n",
       "      <td>17.2000</td>\n",
       "      <td>19.500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>178.0</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>70.00</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.7425</td>\n",
       "      <td>2.355</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.2050</td>\n",
       "      <td>2.135</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color_Intensity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>4.690</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>178.0</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>278.00</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>673.500</td>\n",
       "      <td>985.0000</td>\n",
       "      <td>1680.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_Segment</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.938202</td>\n",
       "      <td>0.775035</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count        mean         std     min       25%  \\\n",
       "Alcohol               178.0   13.000618    0.811827   11.03   12.3625   \n",
       "Malic_Acid            178.0    2.336348    1.117146    0.74    1.6025   \n",
       "Ash                   178.0    2.366517    0.274344    1.36    2.2100   \n",
       "Ash_Alcanity          178.0   19.494944    3.339564   10.60   17.2000   \n",
       "Magnesium             178.0   99.741573   14.282484   70.00   88.0000   \n",
       "Total_Phenols         178.0    2.295112    0.625851    0.98    1.7425   \n",
       "Flavanoids            178.0    2.029270    0.998859    0.34    1.2050   \n",
       "Nonflavanoid_Phenols  178.0    0.361854    0.124453    0.13    0.2700   \n",
       "Proanthocyanins       178.0    1.590899    0.572359    0.41    1.2500   \n",
       "Color_Intensity       178.0    5.058090    2.318286    1.28    3.2200   \n",
       "Hue                   178.0    0.957449    0.228572    0.48    0.7825   \n",
       "OD280                 178.0    2.611685    0.709990    1.27    1.9375   \n",
       "Proline               178.0  746.893258  314.907474  278.00  500.5000   \n",
       "Customer_Segment      178.0    1.938202    0.775035    1.00    1.0000   \n",
       "\n",
       "                          50%       75%      max  \n",
       "Alcohol                13.050   13.6775    14.83  \n",
       "Malic_Acid              1.865    3.0825     5.80  \n",
       "Ash                     2.360    2.5575     3.23  \n",
       "Ash_Alcanity           19.500   21.5000    30.00  \n",
       "Magnesium              98.000  107.0000   162.00  \n",
       "Total_Phenols           2.355    2.8000     3.88  \n",
       "Flavanoids              2.135    2.8750     5.08  \n",
       "Nonflavanoid_Phenols    0.340    0.4375     0.66  \n",
       "Proanthocyanins         1.555    1.9500     3.58  \n",
       "Color_Intensity         4.690    6.2000    13.00  \n",
       "Hue                     0.965    1.1200     1.71  \n",
       "OD280                   2.780    3.1700     4.00  \n",
       "Proline               673.500  985.0000  1680.00  \n",
       "Customer_Segment        2.000    3.0000     3.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Alcohol               178 non-null    float64\n",
      " 1   Malic_Acid            178 non-null    float64\n",
      " 2   Ash                   178 non-null    float64\n",
      " 3   Ash_Alcanity          178 non-null    float64\n",
      " 4   Magnesium             178 non-null    int64  \n",
      " 5   Total_Phenols         178 non-null    float64\n",
      " 6   Flavanoids            178 non-null    float64\n",
      " 7   Nonflavanoid_Phenols  178 non-null    float64\n",
      " 8   Proanthocyanins       178 non-null    float64\n",
      " 9   Color_Intensity       178 non-null    float64\n",
      " 10  Hue                   178 non-null    float64\n",
      " 11  OD280                 178 non-null    float64\n",
      " 12  Proline               178 non-null    int64  \n",
      " 13  Customer_Segment      178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: Customer_Segment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.Customer_Segment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13.05</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>107</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.03</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.880</td>\n",
       "      <td>3.35</td>\n",
       "      <td>885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.580</td>\n",
       "      <td>1.55</td>\n",
       "      <td>640</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12.70</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.780</td>\n",
       "      <td>1.29</td>\n",
       "      <td>600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.51</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>19.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.54</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.100</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>102</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.030</td>\n",
       "      <td>3.52</td>\n",
       "      <td>770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.120</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>12.29</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.21</td>\n",
       "      <td>20.4</td>\n",
       "      <td>103</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.82</td>\n",
       "      <td>870</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.41</td>\n",
       "      <td>20.5</td>\n",
       "      <td>100</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.86</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.040</td>\n",
       "      <td>3.47</td>\n",
       "      <td>920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.130</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.68</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.36</td>\n",
       "      <td>17.2</td>\n",
       "      <td>104</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.84</td>\n",
       "      <td>1.230</td>\n",
       "      <td>2.87</td>\n",
       "      <td>990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13.28</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.84</td>\n",
       "      <td>15.5</td>\n",
       "      <td>110</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.36</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1.090</td>\n",
       "      <td>2.78</td>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>11.81</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.74</td>\n",
       "      <td>21.5</td>\n",
       "      <td>134</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.950</td>\n",
       "      <td>2.26</td>\n",
       "      <td>625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>13.56</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.46</td>\n",
       "      <td>20.5</td>\n",
       "      <td>116</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.45</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.980</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.28</td>\n",
       "      <td>22.5</td>\n",
       "      <td>84</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.880</td>\n",
       "      <td>2.42</td>\n",
       "      <td>488</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.24</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.29</td>\n",
       "      <td>17.5</td>\n",
       "      <td>103</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.820</td>\n",
       "      <td>3.00</td>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.22</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.51</td>\n",
       "      <td>13.2</td>\n",
       "      <td>128</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.890</td>\n",
       "      <td>3.53</td>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>13.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.42</td>\n",
       "      <td>14.0</td>\n",
       "      <td>111</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.87</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>12.25</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.17</td>\n",
       "      <td>510</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>13.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.92</td>\n",
       "      <td>18.0</td>\n",
       "      <td>94</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.230</td>\n",
       "      <td>2.46</td>\n",
       "      <td>630</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.120</td>\n",
       "      <td>3.82</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.050</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>13.74</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.25</td>\n",
       "      <td>16.4</td>\n",
       "      <td>118</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.62</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.920</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.220</td>\n",
       "      <td>2.87</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.960</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>11.56</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.23</td>\n",
       "      <td>28.5</td>\n",
       "      <td>119</td>\n",
       "      <td>3.18</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.87</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.930</td>\n",
       "      <td>3.69</td>\n",
       "      <td>465</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12.60</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.5</td>\n",
       "      <td>94</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.730</td>\n",
       "      <td>1.58</td>\n",
       "      <td>695</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.28</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.120</td>\n",
       "      <td>3.18</td>\n",
       "      <td>502</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>88</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.890</td>\n",
       "      <td>2.78</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>113</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.570</td>\n",
       "      <td>1.33</td>\n",
       "      <td>550</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>11.45</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.800</td>\n",
       "      <td>3.39</td>\n",
       "      <td>625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.800</td>\n",
       "      <td>3.38</td>\n",
       "      <td>438</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>11.87</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.39</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.750</td>\n",
       "      <td>3.64</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12.81</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.40</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1.36</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>12.77</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2.12</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>19.4</td>\n",
       "      <td>107</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.250</td>\n",
       "      <td>3.40</td>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "44     13.05        1.77  2.10          17.0        107           3.00   \n",
       "154    12.58        1.29  2.10          20.0        103           1.48   \n",
       "133    12.70        3.55  2.36          21.5        106           1.70   \n",
       "34     13.51        1.80  2.65          19.0        110           2.35   \n",
       "21     12.93        3.80  2.65          18.6        102           2.41   \n",
       "37     13.05        1.65  2.55          18.0         98           2.45   \n",
       "70     12.29        1.61  2.21          20.4        103           1.10   \n",
       "35     13.48        1.81  2.41          20.5        100           2.70   \n",
       "25     13.05        2.05  3.22          25.0        124           2.63   \n",
       "13     14.75        1.73  2.39          11.4         91           3.10   \n",
       "32     13.68        1.83  2.36          17.2        104           2.42   \n",
       "36     13.28        1.64  2.84          15.5        110           2.60   \n",
       "96     11.81        2.12  2.74          21.5        134           1.60   \n",
       "55     13.56        1.73  2.46          20.5        116           2.96   \n",
       "107    12.72        1.75  2.28          22.5         84           1.38   \n",
       "43     13.24        3.98  2.29          17.5        103           2.64   \n",
       "39     14.22        3.99  2.51          13.2        128           3.00   \n",
       "52     13.82        1.75  2.42          14.0        111           3.88   \n",
       "106    12.25        1.73  2.12          19.0         80           1.65   \n",
       "62     13.67        1.25  1.92          18.0         94           2.10   \n",
       "24     13.50        1.81  2.61          20.0         96           2.53   \n",
       "1      13.20        1.78  2.14          11.2        100           2.65   \n",
       "54     13.74        1.67  2.25          16.4        118           2.60   \n",
       "63     12.37        1.13  2.16          19.0         87           3.50   \n",
       "19     13.64        3.10  2.56          15.2        116           2.70   \n",
       "121    11.56        2.05  3.23          28.5        119           3.18   \n",
       "135    12.60        2.46  2.20          18.5         94           1.62   \n",
       "66     13.11        1.01  1.70          15.0         78           2.98   \n",
       "128    12.37        1.63  2.30          24.5         88           2.22   \n",
       "149    13.08        3.90  2.36          21.5        113           1.41   \n",
       "120    11.45        2.40  2.42          20.0         96           2.90   \n",
       "102    12.34        2.45  2.46          21.0         98           2.56   \n",
       "124    11.87        4.31  2.39          21.0         82           2.86   \n",
       "132    12.81        2.31  2.40          24.0         98           1.15   \n",
       "118    12.77        3.43  1.98          16.0         80           1.63   \n",
       "28     13.87        1.90  2.80          19.4        107           2.95   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity  \\\n",
       "44         3.00                  0.28             2.03             5.04   \n",
       "154        0.58                  0.53             1.40             7.60   \n",
       "133        1.20                  0.17             0.84             5.00   \n",
       "34         2.53                  0.29             1.54             4.20   \n",
       "21         2.41                  0.25             1.98             4.50   \n",
       "37         2.43                  0.29             1.44             4.25   \n",
       "70         1.02                  0.37             1.46             3.05   \n",
       "35         2.98                  0.26             1.86             5.10   \n",
       "25         2.68                  0.47             1.92             3.58   \n",
       "13         3.69                  0.43             2.81             5.40   \n",
       "32         2.69                  0.42             1.97             3.84   \n",
       "36         2.68                  0.34             1.36             4.60   \n",
       "96         0.99                  0.14             1.56             2.50   \n",
       "55         2.78                  0.20             2.45             6.25   \n",
       "107        1.76                  0.48             1.63             3.30   \n",
       "43         2.63                  0.32             1.66             4.36   \n",
       "39         3.04                  0.20             2.08             5.10   \n",
       "52         3.74                  0.32             1.87             7.05   \n",
       "106        2.03                  0.37             1.63             3.40   \n",
       "62         1.79                  0.32             0.73             3.80   \n",
       "24         2.61                  0.28             1.66             3.52   \n",
       "1          2.76                  0.26             1.28             4.38   \n",
       "54         2.90                  0.21             1.62             5.85   \n",
       "63         3.10                  0.19             1.87             4.45   \n",
       "19         3.03                  0.17             1.66             5.10   \n",
       "121        5.08                  0.47             1.87             6.00   \n",
       "135        0.66                  0.63             0.94             7.10   \n",
       "66         3.18                  0.26             2.28             5.30   \n",
       "128        2.45                  0.40             1.90             2.12   \n",
       "149        1.39                  0.34             1.14             9.40   \n",
       "120        2.79                  0.32             1.83             3.25   \n",
       "102        2.11                  0.34             1.31             2.80   \n",
       "124        3.03                  0.21             2.91             2.80   \n",
       "132        1.09                  0.27             0.83             5.70   \n",
       "118        1.25                  0.43             0.83             3.40   \n",
       "28         2.97                  0.37             1.76             4.50   \n",
       "\n",
       "       Hue  OD280  Proline  Customer_Segment  \n",
       "44   0.880   3.35      885                 1  \n",
       "154  0.580   1.55      640                 3  \n",
       "133  0.780   1.29      600                 3  \n",
       "34   1.100   2.87     1095                 1  \n",
       "21   1.030   3.52      770                 1  \n",
       "37   1.120   2.51     1105                 1  \n",
       "70   0.906   1.82      870                 2  \n",
       "35   1.040   3.47      920                 1  \n",
       "25   1.130   3.20      830                 1  \n",
       "13   1.250   2.73     1150                 1  \n",
       "32   1.230   2.87      990                 1  \n",
       "36   1.090   2.78      880                 1  \n",
       "96   0.950   2.26      625                 2  \n",
       "55   0.980   3.03     1120                 1  \n",
       "107  0.880   2.42      488                 2  \n",
       "43   0.820   3.00      680                 1  \n",
       "39   0.890   3.53      760                 1  \n",
       "52   1.010   3.26     1190                 1  \n",
       "106  1.000   3.17      510                 2  \n",
       "62   1.230   2.46      630                 2  \n",
       "24   1.120   3.82      845                 1  \n",
       "1    1.050   3.40     1050                 1  \n",
       "54   0.920   3.20     1060                 1  \n",
       "63   1.220   2.87      420                 2  \n",
       "19   0.960   3.36      845                 1  \n",
       "121  0.930   3.69      465                 2  \n",
       "135  0.730   1.58      695                 3  \n",
       "66   1.120   3.18      502                 2  \n",
       "128  0.890   2.78      342                 2  \n",
       "149  0.570   1.33      550                 3  \n",
       "120  0.800   3.39      625                 2  \n",
       "102  0.800   3.38      438                 2  \n",
       "124  0.750   3.64      380                 2  \n",
       "132  0.660   1.36      560                 3  \n",
       "118  0.700   2.12      372                 2  \n",
       "28   1.250   3.40      915                 1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 44, 154, 133,  34,  21,  37,  70,  35,  25,  13,  32,  36,  96,\n",
       "             55, 107,  43,  39,  52, 106,  62,  24,   1,  54,  63,  19, 121,\n",
       "            135,  66, 128, 149, 120, 102, 124, 132, 118,  28],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataframe.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = dataframe.drop(val_dataframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 142 samples for training and 36 for validation\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TWIST #1\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = to_categorical(dataframe.pop(\"Customer_Segment\"))\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 17:16:28.077159: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'Alcohol': <tf.Tensor: shape=(), dtype=float64, numpy=13.56>, 'Malic_Acid': <tf.Tensor: shape=(), dtype=float64, numpy=1.71>, 'Ash': <tf.Tensor: shape=(), dtype=float64, numpy=2.31>, 'Ash_Alcanity': <tf.Tensor: shape=(), dtype=float64, numpy=16.2>, 'Magnesium': <tf.Tensor: shape=(), dtype=int64, numpy=117>, 'Total_Phenols': <tf.Tensor: shape=(), dtype=float64, numpy=3.15>, 'Flavanoids': <tf.Tensor: shape=(), dtype=float64, numpy=3.29>, 'Nonflavanoid_Phenols': <tf.Tensor: shape=(), dtype=float64, numpy=0.34>, 'Proanthocyanins': <tf.Tensor: shape=(), dtype=float64, numpy=2.34>, 'Color_Intensity': <tf.Tensor: shape=(), dtype=float64, numpy=6.13>, 'Hue': <tf.Tensor: shape=(), dtype=float64, numpy=0.95>, 'OD280': <tf.Tensor: shape=(), dtype=float64, numpy=3.38>, 'Proline': <tf.Tensor: shape=(), dtype=int64, numpy=795>}\n",
      "Target: tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Why use batch?\n",
    "# A: \n",
    "train_ds = train_ds.batch(5)\n",
    "val_ds = val_ds.batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol= keras.Input(shape=(1,), name=\"Alcohol\")\n",
    "malic_acid= keras.Input(shape=(1,), name=\"Malic_Acid\")\n",
    "ash= keras.Input(shape=(1,), name=\"Ash\")\n",
    "ash_alcanity= keras.Input(shape=(1,), name=\"Ash_Alcanity\")\n",
    "magnesium= keras.Input(shape=(1,), name=\"Magnesium\")\n",
    "total_phenols= keras.Input(shape=(1,), name=\"Total_Phenols\")\n",
    "flavanoids= keras.Input(shape=(1,), name=\"Flavanoids\")\n",
    "nonflavanoid_phenols= keras.Input(shape=(1,), name=\"Nonflavanoid_Phenols\")\n",
    "proanthocyanins= keras.Input(shape=(1,), name=\"Proanthocyanins\")\n",
    "color_intensity= keras.Input(shape=(1,), name=\"Color_Intensity\")\n",
    "hue= keras.Input(shape=(1,), name=\"Hue\")\n",
    "od280= keras.Input(shape=(1,), name=\"OD280\")\n",
    "proline= keras.Input(shape=(1,), name=\"Proline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = [\n",
    "    alcohol,\n",
    "    malic_acid,\n",
    "    ash,\n",
    "    ash_alcanity,\n",
    "    magnesium,\n",
    "    total_phenols,\n",
    "    flavanoids,\n",
    "    nonflavanoid_phenols,\n",
    "    proanthocyanins,\n",
    "    color_intensity,\n",
    "    hue,\n",
    "    od280,\n",
    "    proline,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "alcohol= encode_numerical_feature(alcohol, \"Alcohol\", train_ds)\n",
    "malic_acid= encode_numerical_feature(malic_acid, \"Malic_Acid\", train_ds)\n",
    "ash= encode_numerical_feature(ash, \"Ash\", train_ds)\n",
    "ash_alcanity= encode_numerical_feature(ash_alcanity, \"Ash_Alcanity\", train_ds)\n",
    "magnesium= encode_numerical_feature(magnesium, \"Magnesium\", train_ds)\n",
    "total_phenols= encode_numerical_feature(total_phenols, \"Total_Phenols\", train_ds)\n",
    "flavanoids= encode_numerical_feature(flavanoids, \"Flavanoids\", train_ds)\n",
    "nonflavanoid_phenols= encode_numerical_feature(nonflavanoid_phenols, \"Nonflavanoid_Phenols\", train_ds)\n",
    "proanthocyanins= encode_numerical_feature(proanthocyanins, \"Proanthocyanins\", train_ds)\n",
    "color_intensity= encode_numerical_feature(color_intensity, \"Color_Intensity\", train_ds)\n",
    "hue= encode_numerical_feature(hue, \"Hue\", train_ds)\n",
    "od280= encode_numerical_feature(od280, \"OD280\", train_ds)\n",
    "proline= encode_numerical_feature(proline, \"Proline\", train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        alcohol,\n",
    "        malic_acid,\n",
    "        ash,\n",
    "        ash_alcanity,\n",
    "        magnesium,\n",
    "        total_phenols,\n",
    "        flavanoids,\n",
    "        nonflavanoid_phenols,\n",
    "        proanthocyanins,\n",
    "        color_intensity,\n",
    "        hue,\n",
    "        od280,\n",
    "        proline,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# PLOT TWIST #2\n",
    "output = layers.Dense(4, activation=\"softmax\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "\n",
    "# PLOT TWIST #3\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Alcohol (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Malic_Acid (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Ash (InputLayer)               [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Ash_Alcanity (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Magnesium (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Total_Phenols (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Flavanoids (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Nonflavanoid_Phenols (InputLay  [(None, 1)]         0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " Proanthocyanins (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Color_Intensity (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Hue (InputLayer)               [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " OD280 (InputLayer)             [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Proline (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 1)            3           ['Alcohol[0][0]']                \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 1)           3           ['Malic_Acid[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 1)           3           ['Ash[0][0]']                    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_3 (Normalization  (None, 1)           3           ['Ash_Alcanity[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_4 (Normalization  (None, 1)           3           ['Magnesium[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_5 (Normalization  (None, 1)           3           ['Total_Phenols[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_6 (Normalization  (None, 1)           3           ['Flavanoids[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_7 (Normalization  (None, 1)           3           ['Nonflavanoid_Phenols[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_8 (Normalization  (None, 1)           3           ['Proanthocyanins[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_9 (Normalization  (None, 1)           3           ['Color_Intensity[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_10 (Normalizatio  (None, 1)           3           ['Hue[0][0]']                    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " normalization_11 (Normalizatio  (None, 1)           3           ['OD280[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " normalization_12 (Normalizatio  (None, 1)           3           ['Proline[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 13)           0           ['normalization[0][0]',          \n",
      "                                                                  'normalization_1[0][0]',        \n",
      "                                                                  'normalization_2[0][0]',        \n",
      "                                                                  'normalization_3[0][0]',        \n",
      "                                                                  'normalization_4[0][0]',        \n",
      "                                                                  'normalization_5[0][0]',        \n",
      "                                                                  'normalization_6[0][0]',        \n",
      "                                                                  'normalization_7[0][0]',        \n",
      "                                                                  'normalization_8[0][0]',        \n",
      "                                                                  'normalization_9[0][0]',        \n",
      "                                                                  'normalization_10[0][0]',       \n",
      "                                                                  'normalization_11[0][0]',       \n",
      "                                                                  'normalization_12[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           448         ['concatenate[0][0]']            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            132         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 619\n",
      "Trainable params: 580\n",
      "Non-trainable params: 39\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE about Dropout layer:__  \n",
    "The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting\n",
    "\n",
    "__Results without Dropout layer:__\n",
    "Epoch 100/100  \n",
    "29/29 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9722\n",
    "\n",
    "\n",
    "__Results with Dropout layer:__  \n",
    "Epoch 100/100  \n",
    "29/29 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 10ms/step - loss: 1.5368 - accuracy: 0.3099 - val_loss: 1.3476 - val_accuracy: 0.3056\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.2393 - accuracy: 0.4437 - val_loss: 1.1107 - val_accuracy: 0.5833\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.0086 - accuracy: 0.5634 - val_loss: 0.9279 - val_accuracy: 0.7222\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8065 - accuracy: 0.6831 - val_loss: 0.7912 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.7817 - val_loss: 0.6846 - val_accuracy: 0.8611\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.8169 - val_loss: 0.5994 - val_accuracy: 0.8889\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.8521 - val_loss: 0.5218 - val_accuracy: 0.8889\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.9014 - val_loss: 0.4594 - val_accuracy: 0.8889\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8944 - val_loss: 0.4089 - val_accuracy: 0.8889\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8944 - val_loss: 0.3672 - val_accuracy: 0.8889\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.9085 - val_loss: 0.3316 - val_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3157 - accuracy: 0.9155 - val_loss: 0.3123 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8944 - val_loss: 0.2816 - val_accuracy: 0.9167\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.9225 - val_loss: 0.2644 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9648 - val_loss: 0.2493 - val_accuracy: 0.9167\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9507 - val_loss: 0.2339 - val_accuracy: 0.9722\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1910 - accuracy: 0.9366 - val_loss: 0.2279 - val_accuracy: 0.9444\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9366 - val_loss: 0.2167 - val_accuracy: 0.9444\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9718 - val_loss: 0.2042 - val_accuracy: 0.9722\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9507 - val_loss: 0.1827 - val_accuracy: 0.9722\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1887 - accuracy: 0.9366 - val_loss: 0.1777 - val_accuracy: 0.9722\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9437 - val_loss: 0.1653 - val_accuracy: 0.9722\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9789 - val_loss: 0.1577 - val_accuracy: 0.9722\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9296 - val_loss: 0.1567 - val_accuracy: 0.9722\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9507 - val_loss: 0.1501 - val_accuracy: 0.9722\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9718 - val_loss: 0.1464 - val_accuracy: 0.9722\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9718 - val_loss: 0.1423 - val_accuracy: 0.9722\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9789 - val_loss: 0.1344 - val_accuracy: 0.9722\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9648 - val_loss: 0.1234 - val_accuracy: 0.9722\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9648 - val_loss: 0.1168 - val_accuracy: 0.9722\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.9789 - val_loss: 0.1152 - val_accuracy: 0.9722\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9648 - val_loss: 0.1139 - val_accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9722\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9722\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9648 - val_loss: 0.1030 - val_accuracy: 0.9722\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9789 - val_loss: 0.1009 - val_accuracy: 0.9722\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9718 - val_loss: 0.0974 - val_accuracy: 0.9722\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9718 - val_loss: 0.0970 - val_accuracy: 0.9722\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9859 - val_loss: 0.0922 - val_accuracy: 0.9722\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9789 - val_loss: 0.0896 - val_accuracy: 0.9722\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9930 - val_loss: 0.0879 - val_accuracy: 0.9722\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9859 - val_loss: 0.0855 - val_accuracy: 0.9722\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9859 - val_loss: 0.0859 - val_accuracy: 0.9722\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9930 - val_loss: 0.0817 - val_accuracy: 0.9722\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9859 - val_loss: 0.0780 - val_accuracy: 0.9722\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9859 - val_loss: 0.0758 - val_accuracy: 0.9722\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9789 - val_loss: 0.0758 - val_accuracy: 0.9722\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9930 - val_loss: 0.0764 - val_accuracy: 0.9722\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9930 - val_loss: 0.0811 - val_accuracy: 0.9722\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9789 - val_loss: 0.0837 - val_accuracy: 0.9722\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9722\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9859 - val_loss: 0.0804 - val_accuracy: 0.9722\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.0809 - val_accuracy: 0.9722\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9930 - val_loss: 0.0815 - val_accuracy: 0.9444\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9718 - val_loss: 0.0780 - val_accuracy: 0.9722\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9859 - val_loss: 0.0741 - val_accuracy: 0.9722\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9722\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9930 - val_loss: 0.0768 - val_accuracy: 0.9722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9859 - val_loss: 0.0742 - val_accuracy: 0.9722\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9722\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9722\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9930 - val_loss: 0.0712 - val_accuracy: 0.9722\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9930 - val_loss: 0.0729 - val_accuracy: 0.9722\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9930 - val_loss: 0.0716 - val_accuracy: 0.9722\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.0638 - val_accuracy: 0.9722\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9930 - val_loss: 0.0595 - val_accuracy: 0.9722\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9722\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9718 - val_loss: 0.0601 - val_accuracy: 0.9722\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9859 - val_loss: 0.0571 - val_accuracy: 0.9722\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9722\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9930 - val_loss: 0.0607 - val_accuracy: 0.9722\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9722\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9930 - val_loss: 0.0602 - val_accuracy: 0.9722\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9722\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9722\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9722\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9859 - val_loss: 0.0597 - val_accuracy: 0.9722\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9859 - val_loss: 0.0612 - val_accuracy: 0.9722\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9930 - val_loss: 0.0631 - val_accuracy: 0.9722\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9930 - val_loss: 0.0618 - val_accuracy: 0.9722\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9930 - val_loss: 0.0604 - val_accuracy: 0.9722\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 0.0583 - val_accuracy: 0.9722\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9859 - val_loss: 0.0546 - val_accuracy: 0.9722\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9930 - val_loss: 0.0566 - val_accuracy: 0.9722\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9722\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9722\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9789 - val_loss: 0.0573 - val_accuracy: 0.9722\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9789 - val_loss: 0.0559 - val_accuracy: 0.9722\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9722\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.0513 - val_accuracy: 0.9722\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9930 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9930 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9859 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0490 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9728f5cac0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>14.16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.24</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>660</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0      14.23        1.71  2.43          15.6        127           2.80   \n",
       "1      13.20        1.78  2.14          11.2        100           2.65   \n",
       "2      13.16        2.36  2.67          18.6        101           2.80   \n",
       "3      14.37        1.95  2.50          16.8        113           3.85   \n",
       "4      13.24        2.59  2.87          21.0        118           2.80   \n",
       "..       ...         ...   ...           ...        ...            ...   \n",
       "172    14.16        2.51  2.48          20.0         91           1.68   \n",
       "173    13.71        5.65  2.45          20.5         95           1.68   \n",
       "174    13.40        3.91  2.48          23.0        102           1.80   \n",
       "175    13.27        4.28  2.26          20.0        120           1.59   \n",
       "176    13.17        2.59  2.37          20.0        120           1.65   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "172        0.70                  0.44             1.24             9.70  0.62   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "\n",
       "     OD280  Proline  Customer_Segment  \n",
       "0     3.92     1065                 1  \n",
       "1     3.40     1050                 1  \n",
       "2     3.17     1185                 1  \n",
       "3     3.45     1480                 1  \n",
       "4     2.93      735                 1  \n",
       "..     ...      ...               ...  \n",
       "172   1.71      660                 3  \n",
       "173   1.74      740                 3  \n",
       "174   1.56      750                 3  \n",
       "175   1.56      835                 3  \n",
       "176   1.62      840                 3  \n",
       "\n",
       "[177 rows x 14 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample with your own\n",
    "test = dataframe.head(-1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/setel/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/var/folders/ks/l2fhkrzd6f1fd06j0ptvfv600000gn/T/ipykernel_2715/818961304.py:3: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  sample = test.to_dict('r')[0]\n"
     ]
    }
   ],
   "source": [
    "# shortcut to convert dataframe to dict\n",
    "test.drop('Customer_Segment',axis=1,inplace=True)\n",
    "sample = test.to_dict('r')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alcohol': 14.23,\n",
       " 'Malic_Acid': 1.71,\n",
       " 'Ash': 2.43,\n",
       " 'Ash_Alcanity': 15.6,\n",
       " 'Magnesium': 127,\n",
       " 'Total_Phenols': 2.8,\n",
       " 'Flavanoids': 3.06,\n",
       " 'Nonflavanoid_Phenols': 0.28,\n",
       " 'Proanthocyanins': 2.29,\n",
       " 'Color_Intensity': 5.64,\n",
       " 'Hue': 1.04,\n",
       " 'OD280': 3.92,\n",
       " 'Proline': 1065}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alcohol': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.23], dtype=float32)>,\n",
       " 'Malic_Acid': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.71], dtype=float32)>,\n",
       " 'Ash': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.43], dtype=float32)>,\n",
       " 'Ash_Alcanity': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([15.6], dtype=float32)>,\n",
       " 'Magnesium': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([127], dtype=int32)>,\n",
       " 'Total_Phenols': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.8], dtype=float32)>,\n",
       " 'Flavanoids': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.06], dtype=float32)>,\n",
       " 'Nonflavanoid_Phenols': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.28], dtype=float32)>,\n",
       " 'Proanthocyanins': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.29], dtype=float32)>,\n",
       " 'Color_Intensity': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.64], dtype=float32)>,\n",
       " 'Hue': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.04], dtype=float32)>,\n",
       " 'OD280': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.92], dtype=float32)>,\n",
       " 'Proline': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1065], dtype=int32)>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.3858284e-07, 9.9999726e-01, 1.6531454e-06, 1.4392015e-07]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    " np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000 1.000 0.000 0.000]\n"
     ]
    }
   ],
   "source": [
    "for res in predictions:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
